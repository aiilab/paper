% vim:ts=4:sw=4
% Copyright (c) 2014 Casper Ti. Vector
% Public domain.
\chapter{基于度量学习的人脸确认与辨识}
\section{人脸识别研究概述}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%对人脸识别等视觉任务而言， 特征表示和模式分类是两个核心的步骤， 其中又以特征提取最为关键。 过去几十年， 人脸识别的发展史在很大程度上是用来表示人脸特征方法的变迁史。 最早的 人脸识别 文献大多采用 直觉上“有效” 的面部几何特征描述（ 如嘴巴大小等） 来表示人脸，但实践很快表明了其区分力的不足。 1991 年之后， 以“Eigenfaces”为 代表的 子空 间 分析方法在人脸识别领域几乎一统天下，衍生出 Fisherfaces, Laplacianfaces 以及 2D PCA, 2D LDA 等不计其数的子空间分析方法。 这些方法直接采用人脸图像中所有像素的颜色或亮度值作为初始特征， 然后对它们进行“变换” 得到更具区分力的人脸表示。 所采用的“变换” 通常是在训练集合上学习而来的， 最经典的优化目 标是最大化 Fisher 判别准则， 即类内差异小且类间差异大。 为克服上述方法直接以“颜色或亮度值” 作为原始 特征 的 局 限性， 2000 年 之后， 涌现出很多对邻域像素亮度或颜色值进行局部特征提取的方法， 其中既包括在图像分类领域取得极大成功的 S IFT1, HOG2 等局部特征， 也包括尤其适用于人脸 分 析 的 LB P3 和 Gabor 特 征。这类方法的共同特点是汇聚局部邻域像素团的亮度值形成局部特征， 再采用子空间分析等方法对局部特征进行特征变换。 在深度学习浪潮“爆发” 之前， 这类方法在人脸识别领域最真实的 3 个数据库――FERET, FRGC v2.0 和LFW上均取得最高的性能。例如，在美国 国 家标准与 技术研究院(National Institute of Standards and Technology, NIST) 发布的 FERET和 FRGC v2.0 上， 性能最优的方
%法包括中科院计算所视觉信息处理与学习 (Visual Information Processing and Learning, VIPL) 研究组提出的局部 Gabor 幅相融合二值特征， 并配合特征判别分析的方法 [1, 2]。 再如， 在 LFW 数据集上， 在允许利用有标签外部数据且非限定的测试条件下， 性能最好的方法之一为微软亚洲研究院提出的关键特征点上的高维 LB P特征， 并配合稀疏回归判别特征提取的方法 [3]。 在上述测试条件下， 该方法取得了 95.17\% 的 平均分类精度。
%
%对 LFW 数据库而言， 2014年是其性能得以戏剧性提升的一年。 在 2014 年国 际计算机视觉与模式识别会议 (Conference on Computer Vision and Pattern Recognition 2014, CVPR 2014) 上，两个采用深度学习的团队――来自 脸谱的团队 [4] 和香港中文大学的团队 [5]， 在允许利用有标签外部数据且非限定的测试条件下，分别报告了 97.35\% 和 97.45\% 的平均分类精度， 比前述高维 LB P特征方法的 分类错误率降低了50\%。 上述两个团队均采用了卷积神经网络 (Convolutional Neural Network, CNN) 的变种架构。 其中， 脸谱的 DeepFace 方法强调前端的人脸 3D 对齐和虚拟正面化预处理， 以削弱姿态变化的影
%响 ； 而香港中文大学的 DeepID方法则强调采用多个人脸区块分别训练卷积神经网络， 并最终融合形成人脸特征表示。 最近， 该团队进一步开发了 DeepID2+ 系统， 在上述测 试环境下 取得了99.47\% 的 正确 分类精度， 错误率比 DeepID 降低约 80\%。 需要特别指出的是， 这两个系统能够取得优异性能的另一个重要原因是均采用了大规模的标注人脸数据进行训 练， 而且其训 练图 像的分布与 LFW 测试图像（ 名 人图像） 有一定的相似性。 例如，DeepFace 采用了来自 4030 人的440 万幅人脸图像（ 均来自 社交网络） ； 而 DeepID 则使用了来自10177 人的约 20 万人脸图像（ 均为网络名人图像）。当然， 在 LFW 上取得 99.47\%的正确 分类精度并不代表人脸识 别 技 术 已 经 成 熟。 实 际 上，LFW 数据集仅仅代表了 人脸识别众多应用场景中的一种， 即西方名人新闻照片识别。 人脸识别还有很多其他应用场景， 比如面向银行支付的人脸验证、 面向智能视频监控的人脸识别等， 尤其是后者， 尚处于技术远远不能满足应用需求的状态。 为了实现更为鲁棒和准确的识别， 需要实现更为精确的面部特征定位， 并处理好姿态、 夸张表情和人脸老化等难题。
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
自动人脸识别的经典流程分为三个步骤：人脸检测、人脸特征点定位（又称Face Alignment人脸对齐）、特征提取与分类器设计，如图\ref{fig_facerec_framework}所示。一般而言，狭义的人脸识别指的是“特征提取+分类器”两部分的算法研究。
\begin{figure}[!ht] \centering
  \includegraphics[width=.95\textwidth]{figure/fig_face.eps}
  \bicaption[人脸识别框架]{人脸识别框架~\label{fig_facerec_framework}}{Framework of face recognition}
\end{figure}

对人脸识别等视觉任务而言， 特征表示和模式分类是两个核心的步骤， 其中又以特征提取最为关键。 过去几十年，人脸识别的发展史在很大程度上是用来表示人脸特征方法的变迁史。 最早的人脸识别文献大多采用直觉上“有效” 的面部几何特征描述（ 如嘴巴大小等） 来表示人脸，但实践很快表明了其区分力的不足。 1991 年之后， 以EigenFaces\supercite{turk1991eigenfaces}为代表的子空间分析方法在人脸识别领域几乎一统天下，衍生出FisherFaces\supercite{belhumeur1997eigenfaces}，LaplacianFaces\supercite{he2005face} 以及 2DPCA\supercite{zhang20052d}，2DLDA\supercite{li20052d} 等不计其数的子空间分析方法。 这些方法直接采用人脸图像中所有像素的颜色或亮度值作为初始特征，然后对它们进行“变换” 得到更具区分力的人脸表示。 所采用的“变换” 通常是在训练集合上学习而来的， 最经典的优化目标是最大化 Fisher 判别准则，即类内差异小且类间差异大。为克服上述方法直接以“颜色或亮度值” 作为原始特征的局限性，2000 年之后， 涌现出很多对邻域像素亮度或颜色值进行局部特征提取的方法，其中既包括在图像分类领域取得极大成功的SIFT， HOG等局部特征，也包括尤其适用于人脸分析的LBP和Gabor特征。这类方法的共同特点是汇聚局部邻域像素区域的亮度值形成局部特征，再采用子空间分析等方法对局部特征进行特征变换。

一般而言，人脸识别的研究历史可以分为三个阶段。在第一阶段（1950s-1980s），人脸识别被当作一个一般性的模式识别问题，主流技术基于人脸的几何结构特征。在第二阶段（1990s）人脸识别迅速发展，出现了很多经典的方法，例如，EigenFace，FisherFace和弹性图匹配，此时主流的技术路线为人脸表观建模。在第三阶段（1990s末期到现在），人脸识别的研究不断深入，研究者开始关注面向真实条件的人脸识别问题，主要包括以下四个方面的研究：1）提出不同的人脸空间模型，包括以线性判别分析为代表的线性建模方法，以Kernel方法为代表的非线性建模方法\supercite{kim2002face}和基于3D信息的3D人脸识别方法
\supercite{abate20072d}。2）深入分析和研究影响人脸识别的因素，包括光照不变人脸识别、姿态不变人脸识别和表情不变人脸识别等。3）利用新的特征表示，包括局部描述子（Gabor Face, LBP Face等）和深度学习方法\supercite{parkhi2015deep,parkhi2015deep,Sun2014Deep,sun2014deepid2,Schroff2015FaceNet}。4）利用新的数据源，例如基于视频的人脸识别和基于素描、近红外图像的人脸识别。

在深度学习出现以前，人脸识别方法在特征表示部分一般采用高维人工提取特征（例如，LBP， Gabor等）并进行降维两个步骤，代表性的降维方法有PCA，LDA等子空间学习方法和LPP等流行学习方法。在深度学习方法流行之后，代表性方法为从原始的图像空间直接学习判别性的人脸表示。

2007年以来，LFW数据库成为事实上的真实条件下的人脸识别问题的测试基准。LFW数据集包括来源于因特网的5749人的13233张人脸图像，其中有1680人有两张或以上的图像。LFW的标准测试协议包括6000对人脸的十折确认任务，每折包括300对正例和300对反例，采用十折平均精度作为性能评价指标。自从LFW发布以来，性能被不断刷新。2013年之前，主要技术路线为手工设计特征或基于学习的局部描述子加度量学习。2014年之后，主要技术路线为深度学习。

2014年以来，深度学习加大数据（海量的有标注人脸数据）成为人脸识别领域的主流技术路线，其中两个重要的趋势为：1）网络变大变深。例如：VGGFace\supercite{parkhi2015deep}采用了16层的网络，而谷歌提出的FaceNet\supercite{Schroff2015FaceNet}采用了22 层）。2）数据量不断增大。例如：Facebook提出的DeepFace\supercite{parkhi2015deep}训练集达到400万，而谷歌提出的FaceNet\supercite{Schroff2015FaceNet} 则采用了2亿的数据用于训练，简言之，大数据成为提升人脸识别性能的关键。

在人脸识别领域，LFW\supercite{huang2007labeled}是著名的基准测试集。对LFW数据库而言， 2014年是其性能得以戏剧性提升的一年。 在 2014年国际计算机视觉与模式识别会议 (Conference on Computer Vision and Pattern Recognition 2014, CVPR 2014) 上，Facebook和香港中文大学在允许利用有标签外部数据且非限定的测试条件下，分别报告了 97.35\% 和 97.45\% 的平均分类精度，比前述高维LBP特征方法的分类错误率降低了5\%。 上述两个团队均采用了卷积神经网络 (Convolutional Neural Network, CNN) 的变种架构。 其中， Facebook的DeepFace 方法强调前端的人脸 3D对齐和虚拟正面化预处理， 以削弱姿态变化的影响。而香港中文大学的 DeepID\supercite{Sun2014Deep}方法则强调采用多个人脸区块分别训练卷积神经网络， 并最终融合形成人脸特征表示。 最近，该团队进一步开发了DeepID2+\supercite{sun2014deepid2} 系统， 在上述测试环境下 取得了99.47\% 的正确分类精度， 错误率比 DeepID 降低约1.7\%。 需要特别指出的是， 这两个系统能够取得优异性能的另一个重要原因是均采用了大规模的标注人脸数据进行训练， 而且其训练图像的分布与 LFW 测试图像（ 名 人图像） 有一定的相似性。 例如，DeepFace 采用了来自 4030 人的440 万幅人脸图像（ 均来自 社交网络）；而 DeepID 则使用了来自10177 人的约 20万人脸图像（均为网络名人图像）。当然， 在 LFW 上取得 99.47\%的正确 分类精度并不代表人脸识别技术已经成熟。 实际上，LFW 数据集仅仅代表了 人脸识别众多应用场景中的一种， 即西方名人新闻照片识别。 人脸识别还有很多其他应用场景， 比如面向银行支付的人脸验证、 面向智能视频监控的人脸识别等， 尤其是后者，尚处于技术远远不能满足应用需求的状态。为了实现更为鲁棒和准确的识别，需要实现更为精确的面部特征定位， 并处理好姿态、 夸张表情和人脸老化等难题。

比较目前最好的上述几种方法，可以发现，Facebook的DeepFace将大数据（400万人脸数据）与深度卷积网络相结合，在LFW数据集上对于人脸确认任务逼近了人类的识别精度。其中DeepFace还引入了一个Local Connected卷积结构，在每个空间位置学习单独的卷积核，缺点是会导致参数膨胀，这个结构后来并没有流行起来。 DeepID家族可以看作是DL时代人脸识别领域的一组代表性工作。最早的DeepID网络包括四个卷积层，采用softmax损失函数。DeepID2在DeepID网络的基础上，同时考虑了分类损失（identity loss) 和确认损失（verification loss），这两种损失在Caffe深度学习框架中分别可以采用softmaxwithloss层和contrastive loss 层来实现。DeepID2+则是在DeepID2的基础上，增加了每一层的辅助损失函数（类似Deep Supervised Network)。

Google发表于CVPR2015的工作FaceNet采用了22层的深层卷积网络和海量的人脸数据（800 万人的2亿张图像）以及常用于图像检索任务的Triplet Loss损失函数。值得一提的是，由于人脸类别数达到800万类，如果使用softmax loss，输出层节点将达到800万个，需要至少32GB显存（假设上一个隐层节点1024个，采用单精度浮点数），而Triplet Loss则不需要额外占用显存。FaceNet在LFW数据集上人脸确认任务十折平均精度达到99.63\%，这也是迄今为止正式发表的论文中的最好结果，几乎宣告了LFW数据库从2008年到2015年长达八年之久的性能竞赛的结束。

然而上述最新的识别率都是针对人脸确认的识别率。对于人类识别来讲，前文提到有两个任务。一个是人脸确认（Face Verification），另一个是人脸辨识（Face Identification）。人脸确认是一个二分类问题，其任务是比较两张图片是否是同一个人。而人脸辨识是判断一个人的身份，其问题难度随着人数规模而不断增加，因其本质上属于一个多分类问题。而这两个任务之间却有一些相似的地方，如何利用人脸确认当中成对的标签信息用于人脸辨识任务，是本文关注的问题。在以下内容中，本文将从人脸识别问题当中的人脸确认和人脸辨识两个任务分别展开介绍。
\section{基于单任务度量学习的人脸确认}
\subsection{度量学习概述}
相似或者非相似函数在机器学习、模式识别和数据挖掘领域发挥着重要的作用。比如，K近邻分类器\supercite{Cover1967Nearest}通过一个度量来确定最近邻。在聚类算法中，K-means\supercite{Lloyd1982Least}则依赖于数据点间的距离测量，在信息检索中，文档通常根据与给出查询的相关性的相似值来排序。显然，这些方法的执行都依赖于度量的品质。俗语说：“同种的鸟儿合流飞”，同样，研究者们希望通过度量学习指出样本对的相似程度。通用的距离度量如欧式距离，余弦相似或者Levenshtein距离，往往不能反映数据的特质，所以，研究者们期望设计基于特别任务的度量。然而，人工调制的度量是一个困难且枯燥的过程，因此研究者们希望找到一种方法能够自动的基于数据学到度量的方法。度量学习处理的一般过程如下图\ref{fig_metriclearning_process}所示。
\begin{figure}[!ht] \centering
  \includegraphics[width=.8\textwidth]{figure/fig_metriclearning_process.eps}
  \bicaption[度量学习处理的一般过程]{度量学习处理的一般过程~\label{fig_metriclearning_process}}{The common process in metric learning}
\end{figure}

尽管可以追朔到更早的工作，如Friedman\supercite{friedman1994flexible}, Hastie等\supercite{Hastie1996Discriminant}，Baxter等\supercite{Baxter1998The}，度量学习正真出现在2002年，Xing等人
\supercite{Xing2002Distance}的先驱性工作中将其视作一个凸优化问题，并逐渐成为一个研究热点。在各类顶级会议（ICML2010\footnote{\url{http://www.icml2010.org/tutorials.html}}、 ECCV2010\footnote{\url{http://www.ics.forth.gr/eccv2010/tutorials.php}}、ICCV2011workshop\footnote{\url{http://www.iccv2011.org/authors/workshops/}}、NIPS2011\footnote{\url{http://nips.cc/Conferences/2011/Program/schedule.php?Session=Workshops}} 以及ICML2013\footnote{\url{http://icml.cc/2013/?page_id=41}}）中都有针对该主题的大会报告。

度量学习的目标是通过训练样本提供的信息学习到兴趣问题的度量。比如学习马氏距离（Mahalanobis）$d_M(x,{x}')=\sqrt{(x-{x}')^TM(x-{x}')}$中的半正定矩阵$M$。绝大数的度量学习方法以如下表示成对或三元组约束弱监督的方式：
\begin{equation}
\label{equ_ml_define}
\left\{\begin{matrix}
S={(x_i,x_j):x_i,x_j~similar~pair}\\
D={(x_i,x_j):x_i,x_j~dissimilar~pair}\end{matrix}\right.
\end{equation}

相对约束（训练三元组）为：$T={(x_i,x_j,x_k)}$。其中$x_i$和$x_j$相似，与$x_k$不相似。那么一个度量学习算法的基本目标是找到一系列参数，使其最好地适应限制条件，从而最大程度地逼近底层的语义量度。通常可以写成具有以下形式的最优化问题：
\begin{equation}
\label{equ_ml_convex}
\min_ML (M,S,D,T)+\lambda R(M)
\end{equation}
其中$L(M,S,D,T)$ 为损失函数，当限制条件被违反时，则会触发惩罚，$R(M)$为正则项，调整学习到的度量矩阵$M$，$\lambda$为正则化参数。最新提出的度量学习方法，其本质上的不同大都来自度量的选择、约束条件、损失函数和正则项。度量学习后的阶段，可用于提升与度量相关的算法的性能，如K-NN，聚类算法K-Means，排序算法等。从训练数据学习一个度量并插入一个输出预测的算法（例如，一个分类器，一个回归器，一个推荐系统等），以此希望获得比基于标准度量的预测算法更好的性能。

度量学习算法可从5个关键属性来确定和描述\supercite{bellet2013survey}，如图\ref{fig_metriclearning_keypoints}所示。
\begin{figure}[!ht] \centering
  \includegraphics[width=.8\textwidth]{figure/fig_metriclearning_keypoints.eps}
  \bicaption[度量学习算法的5个关键属性]{度量学习算法的5个关键属性~\label{fig_metriclearning_keypoints}}{Five key properties of metric learning algorithms}
\end{figure}

首先看学习模式（Learning paradigm）。度量学习主要有三种学习模式：

1）全监督式（Fully supervised）：训练算法能够获取到训练实例$\left \{ z_i=(x_i,y_i)\right \}^n_{i=1} $的标签，而每个训练样本$z_i\in Z=X\times Y$是由一个实例$x_i\in X$和一个标签$y_i\in Y$(所属的类别) 组成。$Y$是一个由标签$|Y|$组成的离散有限集合。通常，标签信息被用于产生特定的三元限制，如前面给出的$S,D,R$。

2）弱监督式（Weakly supervised）：训练算法不能获取到训练实例的标签，只能通过集合约束$S,D,R$的形式给出侧面信息。这是很有用的设置，因为在很多应用中标记的数据的代价很昂贵，而提供侧面信息却很方便。这样的例子包括用户的隐反馈（例如，点击搜索引擎结果），在网络中对文章或链接间的引用。这都可以被看作仅在对三重约束情况下的标签信息。

3）半监督式（Semi-supervised）：除了全监督和弱监督方式，半监督式算法能够访问未标记实例的样本（通常数据量很大）并且没有旁侧信息可用。当标记数据或旁侧信息很少的时候，半监督式可以避免过拟合。

度量的形式（Form of metric）：显然，度量形式的选择是一个关键，一般有三大主要度量家族\supercite{bellet2013survey}：1）线性度量(Linear metrics)，如Mahalanobis距离。由于这类距离度量容易优化，计算相对简单，且不容易过拟合（因为通常可表示为凸优化问题，因此可找到全局最优）。2）非线性度量（Nonlinear metrics），比如 直方图距离，非线性度量的形式的缺点是容易引出非凸优化问题，得出的是局部最优，且可能过拟合。优点是能够捕获到数据的非线性特性。3）局部度量（Local metrics）：在局部度量中，多个（线性或者非线性的）局部度量被学习（通常是同步学习到的），从而更好的处理复杂的问题，如异构数据。然而这种形式相比于全局的方法更容易过拟合，因为所学习的参数的数量往往很多。

可扩展性（Scalability）：随着可用数据的迅猛增长，可扩展性成为机器学习领域所有问题需要关注的问题。首先，期望度量学习算法对训练样本的数目具有良好的扩展性。基于此，在线学习是解决方案之一。其次，度量学习方法应对数据的维数也具有可扩展性。然而，度量学习通常表达为学习一个 矩阵的形式，设计基于如此规模的并能够合理扩展的算法依然是一个相当大的挑战。

解的最优性（Optimality of the solution）：这个属性涉及到算法的性能，即找到满足优化准则最优的参数。理想情况下，可通过全局最优来保证。这也是凸函数优化度量学习的关键。与此相反，非凸情况下，解可能仅是局部最优。

维数降低(Dimensionality reduction)：度量学习有时可设计为寻找一个到新的特征空间的映射。而这种方式的一个附加好处在于可以兼顾寻找一个低维度的映射空间，从而使得计算更快，表达更紧凑。而通常情况下，维数降低是通过正则项来驱使学到的度量矩阵是低秩的。

近年来，度量学习方法在人脸识别及Re-ID\supercite{Gong2013Person}等问题上得到了广泛的应用。如何为特定任务来学习适当的距离度量一直是度量学习研究的主要内容。经典的方法有基于最大间隔的多度量学习\supercite{weinberger09distance,parameswaran2010large}以及融合了多种人脸区域描述子的多度量学习算法\supercite{Cui2013Fusing}。 Fu 等人\supercite{Yun2008Correlation}提出了一种学习关联度量（correlation metric）的方法，该度量学习模型在对样本降维后，可以保留样本之间的近邻关系，并针对关联度量提出了相关嵌入分析（CEA，Correlation Embedding Analysis）模型和相关主成分分析（CPCA， Correlational Principle Component Analysis）模型。Guillaumin等人
\supercite{Guillaumin2010Multiple}提出了MildML（Multiple Instance Logistic Discriminant Metric Learning）模型，并在多事例学习中得到了成功的应用。Guillaumin 等人\supercite{Guillaumin2009Is}还提出了LDML（Logistic Discriminant based Metric Learning）模型和MkNN（Marginalized k-nearest neighbor）模型来学习人脸识别中的距离度量。LDML 模型通过将度量学习问题看作基于核的逻辑回归问题，通过极大似然估计来学习距离度量，MkNN 通过学习非线性度量学习模型，来提高模型的判别能力。为了改进已有度量模型的泛化能力，Nguyen 和 Bai 提出了余弦相似度度量学习（CSML）模型\supercite{nguyen2011CSML}，该模型使用余弦相似度来构造目标函数。文献\parencite{Cao2013Similarity}提出了一种Sub-SML的度量学习方法，通过采用马氏距离和余弦相似距离的学习，取得了在单任务学习中目前最高的识别率。

K{\"o}stinger等人\supercite{kissme}提出了KISS 模型用来从恒等约束中学习到距离度量，此外，该模型可以针对大规模的数据集学习距离度量。Huang 等人\supercite{Huang2011Generalized}提出了广义稀疏度量学习模型（Generalized Sparse Metric Learning, GSML），该方法为许多有代表性的稀疏度量学习模型提供了一个统一的角度，并且可以将现有的许多非稀疏度量学习模型扩展到稀疏度量学习形式。Shen等人\supercite{shen2009positive}提出了推动度量（Boost Metric）方法，该方法针对传统度量学习方法中的半定规划问题不能有效地处理大规模数据的缺点，使用类似 boosting 的策略，通过将度量矩阵分解为一系列秩为1的矩阵来学习一组弱分类器，最后将它们组合。在上述方法当中，基于KISSME\supercite{kissme}的方法取得了在单任务学习下较好的效果，并且由于该方法不需要优化，只需要计算相似集和非相似集的协方差矩阵，所以运行效率相比其他方法快很多，可以处理大规模的数据的问题。以下我们先详细地介绍KISSME度量学习的原理，然后再给出我们提出的多任务度量学习方法。

\subsection{基于KISSME的度量学习}
Mahalanobis距离常用于衡量两个特征向量的相似程度，对特征$\bm{x}_i,\bm{x}_j\in \mathbb{R}_d$，其相对距离可计算如下：
\begin{equation}
\label{equ_kissme_distance}
d_M(x,{x}')=\sqrt{(x-{x}')^TM(x-{x}')}
\end{equation}	  	
其中$\bm{M}$是正定的Mahalanobis矩阵。

    KISSME\supercite{kissme}是距离度量学习方法的一种，该方法通过以下函数计算两个特征是否相似，通过定义似然度来衡量输入对的相似程度：
\begin{equation}
\label{equ_kissme_definition}
\delta(\mathbf{x}_i,\mathbf{x}_j)=log\left(\frac{p(\mathbf{x}_{ij}|H_0)}{p(\mathbf{x}_{ij}|H_1)}\right)
=log\left(\frac{f(\mathbf{x}_{ij}|\theta_0)}{f(\mathbf{x}_{ij}|\theta_1)}\right)
\end{equation}
其中$H_0$表示$x_i,x_j$是非相似的，当$\delta(x_i,x_j)$值较大时成立，相反，$H_1$表示$x_i,x_j$是相似的，当$\delta(x_i,x_j)$值较小时成立。

假设特征差$\bm{x}_{ij}=\bm{x}_i-\bm{x}_j$符合高斯分布，问题可转换为：
\begin{equation}
\label{equ_kissme_log}
\delta(\mathbf{x}_i,\mathbf{x}_j)=\log \left ( \frac{\frac{1}{\sqrt{2|\sum_{y_{ij}=0}|}}\exp(-1/2\mathbf{x}^T_{ij}\sqrt{\sum_{y_{ij=0}}^{-1}\mathbf{x}_{ij}})}
{\frac{1}{\sqrt{2|\sum_{y_{ij}=1}|}}\exp(-1/2\mathbf{x}^T_{ij}\sqrt{\sum_{y_{ij=1}}^{-1}\mathbf{x}_{ij}})} \right )
\end{equation}	    	
其中的方差矩阵通过下面公式计算：
\begin{equation}
\label{equ_kissme_cal1}
\Sigma_{y_{i,j=0}}=\sum_{y_{ij=0}}(\mathbf{x}_i,\mathbf{x}_j)(\mathbf{x}_i,\mathbf{x}_j)^T
\end{equation}	
\begin{equation}
\label{equ_kissme_cal2}
\Sigma_{y_{i,j=1}}=\sum_{y_{ij=1}}(\mathbf{x}_i,\mathbf{x}_j)(\mathbf{x}_i,\mathbf{x}_j)^T
\end{equation}		
上式中，当$\mathbf{x}_i,\mathbf{x}_j$相似时，$y_{ij}=1$，反之$y_{ij}=0$。因此，Mahalanobis度量矩阵$M$可以使用如下公式计算：
\begin{equation}
\label{equ_kissme_cal3}
M=\Sigma^{-1}_{y_{ij=1}}-\Sigma^{-1}_{y_{ij=0}}
\end{equation}	
从而避免了迭代优化的过程。在KISSME度量学习实现当中，最耗时的操作是矩阵求逆，由于涉及矩阵求逆，其复杂度是矩阵维度的三次方，即$O(n^3)$。但由于一般在使用 KISSME 的时候需要对特征进行降维，维数一般不会太高，且在整个过程中求逆操作只进行了两次，不需要耗时的迭代过程，因此KISSME的最大优点是训练速度非常快。
\section{基于两级多任务度量学习的人脸辨识}
\subsection{两级多任务度量学习}

KISSME算法的优点在于可以直接求解出度量矩阵，计算简单快速，不需要繁杂的迭代优化过程。KISSME解决单个特征的二分类问题，然而当面对多分类问题并且多种特征时，如何利用KISSME取得更好的分类效果且依旧保持其优点是我们想要解决的问题。因此，我们在KISSME的基础上，对其进行改进，提出双层多任务度量学习（Two-level Mult-Task Learning, TMTL），使其适用于多种特征多个任务的学习，提出的两层多任务学习框架如图\ref{fig_tmtl_framework}所示。第一层学习多特征，第二层计算不同学习任务之间的共享信息机制。
\begin{figure}[ht] \centering
  \includegraphics[width=.8\textwidth]{figure/fig_tmtl_framework.eps}
  \bicaption[多任务度量学习人脸辨识框架]{多任务度量学习人脸辨识框架~\label{fig_tmtl_framework}}{Framework of multi-task metric learning for face identification}
\end{figure}

定义$k\in\left\{1,2,...,K\right\}$是第一层的第$k$种特征。对每个特征类型的每个子任务，以共享度量矩阵$\mathbf{M}^k_0$和特定矩阵$\mathbf{M}^k_t$相结合的形式，计算任务$t\in\left\{1,2,...,T\right\}$的度量矩阵。即第一层为选择对应的特征，第二层是在第一层选定的特征下进行多任务学习。因为我们考虑的是人脸辨识问题，将人脸辨识问题转化为多任务学习是基于这样的观察：大部分的人脸都包含共同的相似的区域，而每个人脸的表达是公共的部分和特有部分的叠加。因此，给出一对训练样本，其距离定义为：
\begin{equation}
\label{equ_tmtl_distance}
d^2_t(\textbf{x}_i,\textbf{x}_j)=\sum^{K}_{k=1}(\textbf{x}_i-\textbf{x}_j)^\text{T}(\mathbf{M}^k_0+\mathbf{M}^k_t)(\textbf{x}_i-\textbf{x}_j)
\end{equation}
每一个任务定义了一个特定任务（task-specific）的相似对和非相似对的子集：$S_t=\left\{(i,j)\in\psi_t|y_i=y_j\right\}$ 和 $D_t=\left\{(i,j)\in\psi_t|y_i\neq y_j\right\}$。根据公式\ref{equ_kissme_cal2}可以得到，第$k$个特征的第$t$个子任务的度量矩阵为：
\begin{equation}
\begin{aligned}
\label{equ_tmtl_distmatrix}
&~~~~~~~~~~~~~~~~~~~~~~\mathbf{M}^k_t=\mathbf{M}^{-1}_{S_t}-\mathbf{M}^{-1}_{D_t}\\
&=\left(\frac{1}{|S_t|}\sum_{(i,j)\in{S_t}}\mathbf{C}_{ij}\right)^{-1}-\left(\frac{1}{|D_t|}\sum_{(i,j)\in{D_t}}\mathbf{C}_{ij}\right)^{-1}
\end{aligned}
\end{equation}
其中，$\mathbf{C}_{ij}=(\textbf{x}_i-\textbf{x}_j)^\text{T}(\textbf{x}_i-\textbf{x}_j)$。因此，在每个特征下的，所有子任务公共的度量矩阵$\mathbf{M}^k_0$可以通过所有子任务的平均估计得到，即：
\begin{equation}
\label{equ_tmtl_shared_matrix}
\mathbf{M}^k_0=\left(\frac{1}{T}\sum_{t=1}^{T}\mathbf{M}_{S_t}\right)^{-1}-\left(\frac{1}{T}\sum_{t=1}^{T}\mathbf{M}_{D_t}\right)^{-1}
\end{equation}
然后，最终的马氏（Mahalanobis）度量矩阵为：
\begin{equation}
\label{equ_tmtl_metrix_final}
\hat{\mathbf{M}}^k_t=\mathbf{M}^k_0+\mu\mathbf{M}^k_t
\end{equation}

相应地，$\mathbf{M}^k_0$表示了对于每个特征在所有子任务上的共同的特性，而$\mathbf{M}_t^k$聚焦于特定任务的特性，其中的平衡因子$\mu$ 在共享度量矩阵$\mathbf{M}^k_0$和特定子任务度量矩阵$\mathbf{M}^k_t$取得平衡。在这里，$\mu$ 是子任务样本所占所有训练样本的比例。总结上述工作，本文提出的两级多任务度量学习算法如算法\ref{alg_tmtl}所示。
\begin{algorithm}[tb]
    \caption{基于两级多任务度量学习框架}\label{alg_tmtl}
    %\SetAlgoNoLine
    \textbf{输入}：{训练数据对$\left\{\textbf{x}_i^k,\textbf{x}^k_j\right\}\in\mathbb{R}^{d_{k}},k=1,2,...,K$, $K$ 是特征总数. 子任务 $t\in\left\{1,2,...,T\right\}$.}

    \textbf{输出}：{最终度量矩阵 $\hat{\mathbf{M}}^k_t\in{R}^{(d_k\times d_k)_t}$.}

    定义一个基于特定任务的相似对 $S_t$ 和 不相似对 $D_t$子集.\\
    计算平衡因子 $\mu$.\\
    \For {$k\gets1$ \KwTo $K$}{
        \For {$t\gets1$ \KwTo $T$}{

            对$S_t$ 和 $D_t$提取第$k$个特征.\\
            根据公式\eqref{equ_tmtl_distmatrix}计算第$k$个特征的特定任务的度量矩阵.\\
            根据公式\eqref{equ_tmtl_shared_matrix}计算共享的度量矩阵.\\
            根据公式\eqref{equ_tmtl_metrix_final}得到最终度量学习矩阵$\hat{\mathbf{M}}^k_t$. \\
        }
    }
    \textbf{返回}：{$\hat{\mathbf{M}}^k_t\in{R}^{(d_k\times d_k)_t}$.}
\end{algorithm}
\vspace{-0.5em}
\subsection{多任务投票}
为了充分利用两级多任务度量学习的方法，所有的基于特定任务的度量矩阵组合起来转化为一个多分类的决策。类似多数投票机制，文献\parencite{friedman1996another}采取了将类别标签赋予获得最多比较对票数的类别。

假设对任务$t$的正样本和类别标签一致，即$\mathbf{x}_i:y_{i}=t$。 给定一个测试样本$\mathbf{x}_i$，投票机制需要确定测试样本属于哪一个任务标签。为了提高比较的鲁棒性，我们不仅采用了任务$t$的单个的度量矩阵进行比较，而且采用了任务$u\in\left \{{u\neq t|u=1,...,T}  \right \}$的度量矩阵进行辅助性的度量。至此，最终的类别标签为获得最多投票次数的子任务标签。为了简明的说明多任务投票机制，给出了算法\ref{alg_multi_task_voting}进行说明。
\begin{algorithm}[htb]
    \caption{多任务投票机制}\label{alg_multi_task_voting}
    %\SetAlgoNoLine

    \textbf{输入}：{距离度量矩阵$\hat{\mathbf{M}}^k_t\in{R}^{(d_k\times d_k)_t}$；每个特定任务的索引集$\psi_t$；测试样本 $\mathbf{x}_i$.}
    \textbf{输出}：{类别标签$c\in\left\{1,2,...,T\right\}$.}

    \textbf{初始化}：$I_t\gets0, Label(t)\gets0, c\gets0, A\gets0, B\gets0$.\\
    \For {$t\gets1$ \KwTo $T$}{
        \While {$u\neq t$, and $u\in\left\{1,2,...,T\right\}$}{
            计算 $A \gets \min\limits_{{j \in \psi_t \wedge y_j=t}} d^2_t(\mathbf{x}_i,\mathbf{x}_j)$.\\
           % Compute $B \gets \min\limits_{{k \in \psi_u \wedge y_k=u}} d^2_t(\mathbf{x}_i,\mathbf{x}_k)$\\
            \If{$A \leq \min\limits_{{k \in \psi_u \wedge y_k=u}} d^2_t(\mathbf{x}_i,\mathbf{x}_k)$}{
                $I_t \gets I_t+1$.
            }

            计算 $B \gets \min\limits_{{j \in \psi_t \wedge y_j=t}} d^2_u(\mathbf{x}_i,\mathbf{x}_j)$.\\
           % Compute $B \gets \min\limits_{{k \in \psi_u \wedge y_k=u}} d^2_t(\mathbf{x}_i,\mathbf{x}_k)$\\
            \If{$B \leq \min\limits_{{k \in \psi_u \wedge y_k=u}} d^2_u(\mathbf{x}_i,\mathbf{x}_k)$}{
                $I_t \gets I_t+1$.
            }
        }
        $Label(t) \gets I_t$.\\
    }
    $c \gets \mathop{\arg\max}\limits_t=Label(t)$.\\
    \textbf{返回}：类别标签 $c$.
\end{algorithm}
\vspace{-0.4cm}
\subsection{算法复杂度分析}
该方法的运算复杂度主要有KISSME度量学习和两级多任务两部分组成，定义特征维度为$n$，两级多任务当中第一级特征个数为$K$，第二级类别个数为$T$，即总共包含$T$个人，类别规模为$T$，每个人有$m$张图片，即$m$个正样本。下面将从训练时间复杂度和测试时间复杂度进行分析。

训练时间复杂度。在KISSME的度量学习当中，可以通过公式(\ref{equ_kissme_cal3})来近似计算马氏度量矩阵$M$。为了保证$M$的半正定性质，可以将矩阵$M$的负特征值变为0，保留非负特征值的方式，即先进行特征值分解：
\begin{equation}
\label{equ_alg_complex}
\hat{M}=X^T \Lambda X
\end{equation}
其中$\hat{M}$是特征向量串联而成，对角阵$\Lambda$的对角元素都为特征值。令
\begin{equation}
\label{equ_alg_complex2}
{\Lambda}'=diag(max(0,\lambda_1),...,max(0,\lambda_n))
\end{equation}
然后重新计算的$M$即满足了半正定的约束，即：
\begin{equation}
\label{equ_alg_complex3}
M=X^T {\Lambda}' X
\end{equation}
上面的计算中，最耗时的操作是矩阵求逆，复杂度是矩阵维度的三次方，即$O(n^3)$，但由于一般在使用 KISSME 的时候需要对特征进行降维，维数一般不会太高，且在整个过程中求逆操作只进行了两次，不需要耗时的迭代过程，因此 KISSME 的最大优点是训练速度非常快。

在两级多任务当中，对于每个特征，都要计算$T$个子任务当中的距离度量矩阵，尽管不同特征的特征维度不一致，但可通过PCA降维归一化到统一的大小。因此，整个两级多任务度量学习训练的时间负责都为：
\begin{equation}
\label{equ_alg_complex4}
O(n^3)O(KT)=O(n^3KT)
\end{equation}
由于n可以看作固定值，而一般特征的个数选择不会很大，所以该问题的复杂度随着第二级当中的子任务规模而增加。这意味着，当需要识别的人数越多，类别标签也越多，训练时间也越长。当$T$远大于$n$和$K$时，算法的复杂度近似于$O(T)$。

测试时间复杂度。对于新来的一个测试样本，其任务是确定该样本的类别标签，即身份信息。在两级多任务度量学习当中，类别标签即为属于最大投票数量的子任务标签。因为子任务$t$的正样本和类别标签是一致的。首先，对于测试样本，首先要与每个子任务$t$的每个正样本计算一次距离，为了保证投票的准确性，还与非当前任务的其它子任务的度量矩阵进行辅助性的度量，因此每个子任务的复杂度为：
\begin{equation}
\label{equ_alg_complex5}
O(m)+ O(T-1)O(m)= O(Tm)
\end{equation}
因其共有$T$个子任务，$K$个特征，所以最终的算法复杂度为：
\begin{equation}
\label{equ_alg_complex5}
O(K)O(T)O(Tm)=O(KT^2m)
\end{equation}
可以看出，最终的测试时间与特征个数和子任务个数以及子任务的正样本都有关系，一般在测试的过程当中，$K$和$m$一般都不会很大，一般为常量。所以，测试时间与类别个数的规模有直接关系。上述算法复杂度的分析将一次距离的比较作为基本的操作，因为算法复杂度为$O(KT^2)$，所以该算法在大规模的人脸辨识中测试将很耗时。一般在类别数目不大时，因其是多项式的复杂度，测试完全能保证实时性。
%\subsection{算法复杂度分析}
\section{本章小结}
本章在人脸检测和人脸特征点定位的基础上进行了人脸识别相关的研究。人脸识别的问题其本质上还是距离度量的问题，其中人脸确认，即是对两张人脸图片相似度的度量，也是距离的度量。而人脸辨识是一个多分类问题，本章在基于KISSME方法之上提出一种多任务度量学习的框架，该方法不但很好的解决了人脸辨识的问题，而且可解决大部分多分类问题。另一方面，由于人脸辨识采用了基于度量学习的方法，本章还对度量学习方法进行了综述，与传统的分类方法相比，度量学习方法能够学习针对数据自身的特点，量身定做出相应的距离描述，从而更好地解决多分类问题。