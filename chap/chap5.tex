% vim:ts=4:sw=4
% Copyright (c) 2014 Casper Ti. Vector
% Public domain.
\chapter{实验结果与分析}
\section{人脸检测结果与分析}
\subsection{实验数据库与设置}
\textbf{FDDB}\supercite{fddbTech}：FDDB（Face Detection Data Set and Benchmark）数据库是目前最大而且最难的公匀肆臣觳馐据库，它是马萨诸塞大学计算机系运营的人脸检测测试平台，所有团队可以通过其包含5171张人脸的2845张图片的测试集来测试检测技术的精度。在平台上，所有参与者都将面对学界、商界挑剔的目光，无论是百度、腾讯这样的互联网巨头，还是技术实力雄厚的技术团队，测试结果都将被公开展示，技术实力的排名被实时更新。它里面包含了各种困难的情况，包括遮挡、不同的角度、低分辨率和失焦的人脸等等。作为全世界最具权威的人脸检测评测平台之一，其公布的评测集也代表了人脸检测的世界最高水平。

这个数据库包含了两种测试方案：离散的方案和连续的方案。在离散的方案中，只有当算法检测到的框和某一个标注的框的重合度大于0.5的时候，这个检测结果才算是正确的。这里的两个框的重合度的定义是两个矩形的交集的面积除以这两个矩形的并集的面积。这种离散的测试方案被广泛的应用在各种物体检测算法评价中。而连续的测试方案指的是每个算法检测到的框和标注的框的重合度会作为权重叠加到每个检测结果上。这个测试方案更加严格，它要求检测出来的框不仅要正确，而且还要稳定，要尽量和标注结果保持一致。

FDDB是在无限制真实条件下获取的人脸图片，其中包含了遮挡、不同角度、低分辨率等照片，这与监控场景下人脸检测所带来的问题一致。因为FDDB是基准数据库，所以我们在该数据库上进行了测试。其测试数据为官方指定的2845张人脸图片。图\ref{fig_fddb}是FDDB数据库的已经人工标记的人脸图片。
\begin{figure}[!ht] \centering
  \includegraphics[width=.9\textwidth]{figure/fig_fddb.eps}
  \bicaption[FDDB多姿态人脸示例]{FDDB多姿态人脸示例~\label{fig_fddb}}{Illustration of pose varied faces in FDDB }
\end{figure}

\subsection{性能评价准则}
由于全世界研究人员的不懈努力，每年都有许多的人脸检测方法甚至是商用人脸检测系统的出现，为了便于统一管理和对这些检测方法进行测评，需要提供一个统一的测试集，并制定一套统一的指标来测试这些不同的方法。为此，世界上一些著名的大学和研究机构都做了自己的工作。人脸检测主要的评价标准有检测率、假阳率、假阴率、及算法执行效率。而检测率、假阳率、假阴率统一在接收者操作特性（Receiver Operating Characteristic,~ROC）曲线\supercite{Zweig1993Receiver}之内，简称“ROC曲线”。因此，本文主要以ROC曲线以及算法执行效率两个方面对人类检测性能进行评价。

（1）ROC曲线

在认识ROC曲线之前，需要先了解以下几个概念：

1、检测率

被正确检测到的人脸数与图像内包含的人脸数的比值。检测率越高，说明检测系统对人脸的接受能力越强。

2．假阳率

也称误检率、虚警率、误报率，定义为负类样本被错误分类为正类的样本数与所有负类样本数的比例。设图像内被检测的所有非人脸子窗口数为$M$ ，被误检为人脸的非人脸子窗口数为$N$ ，则假阳率为$N/M$ 。 检测率无法反映系统对非人脸的排除能力，有可能出现这种情况所有人脸都被检测到，但同时很多非人脸区域被误认为是人脸。因此引入假阳率来衡量系统对非人脸的排除能力。假阳率越低，说明检测系统对非人脸的排除能力越强。

3．假阴率

也称漏检率，即被误检为非人脸的人脸子窗口数与图像内被检测的所有人脸子窗口数的比值。设图像内被检测的所有人脸子窗口数为$M$ ，被误检为非人脸的人脸子窗口数为$N$ ，则假阴率为$N/M$  。

人脸检测本质上是一个二分类问题，基本框架是对一个滑动窗口内的图片进行分类。对一个二分问题来说，会出现四种情况。如果一个实例是正类并且也被预测成正类，即为真正类(True Positive,\~TP)。如果实例是负类被预测成正类，称之为假正类(False Positive,FP)。相应地，如果实例是负类被预测成负类，称之为真负类(True Positive,~TP)，正类被预测成负类则为假负类(False Negative,~FN)。如表
\ref{table_roc}所示，1代表正类，0代表负类。其给出了评价分类器好坏的性能指标，即混淆矩阵。

由表\ref{table_roc}可以得到总共有四个指标。其一是真正类率(True Positive Rate,~TPR)， 计算公式为$TPR=TP/ (TP + FN)$，刻画的是分类器所识别出的正实例占所有正实例的比例。另外一个是负正类率(False Positive Rate,~FPR)，计算公式为$FPR= FP/ (FP + TN)$，计算的是分类器错认为正类的负实例占所有负实例的比例。还有一个真负类率(True Negative Rate,~TNR)，计算公式为$TNR=TN/(FP + TN) = 1-FPR$。
% Please add the following required packages to your document preamble:
% \usepackage{multirow}
\begin{table}[]
\centering
\bicaption[混淆矩阵参数]{混淆矩阵参数~\label{table_roc}}{The parameters of confusion matrix}
\label{my-label}
\begin{tabular}{|l|l|c|l|l|}
\toprule[1.5pt]
\multicolumn{2}{|l|}{\multirow{2}{*}{}}                                                       & \multicolumn{2}{c|}{预测}                                                                                                                                                               &                                  \\ \cline{3-5}
\multicolumn{2}{|l|}{}                                                                        & 人脸                                                                            & \multicolumn{1}{c|}{非人脸}                                                                              & \multicolumn{1}{c|}{\textbf{合计}} \\ \hline
\multirow{2}{*}{\begin{tabular}[c]{@{}l@{}}实  \\    际\end{tabular}} & \multicolumn{1}{c|}{人脸} & True Positive(TP)                                                             & False Negative(FN)                                                                                    & Actual  Positive(TP+FN)          \\ \cline{2-5}
                                                                    & 非人脸                     & \multicolumn{1}{l|}{False Positive(FP)}                                       & True Negative(TN)                                                                                     & Actual Negative(FP+TN)           \\ \hline
\multicolumn{2}{|c|}{\textbf{合计}}                                                             & \begin{tabular}[c]{@{}c@{}}Predicted Positive\\          (TP+FP)\end{tabular} & \multicolumn{1}{c|}{\begin{tabular}[c]{@{}c@{}}Predicted Negative\\             (FN+TN)\end{tabular}} & \multicolumn{1}{c|}{TP+FP+FN+TN} \\ \hline
\toprule[1.5pt]
\end{tabular}
\end{table}

在一个二分类模型中，对于所得到的连续结果，假设已确定一个阀值，比如说0.6，大于这个值的实例划归为正类，小于这个值则划到负类中。如果减小阀值，减到0.5，固然能识别出更多的正类，也就是提高了识别出的正例占所有正例的比类，即TPR，但同时也将更多的负实例当作了正实例，即提高了FPR。为了形象化这一变化，在此引入ROC，英文名为Receiver Operating Characteristic，翻译为“接受者操作特性曲线”。曲线是由两个变量的组合，1-Specificity和Sensitivity。由于1-Specificity=FPR，即负正类率。Sensitivity即是真正类率，True Positive Rate (TPR)，反映了正类覆盖程度。这个组合以1-Specificity对Sensitivity，即以代价(costs)对收益(benefits)。

用ROC曲线来表示分类器的性能很直观好用。可是，人们总是希望能有一个数值来标志分类器的好坏，于是Area Under roc Curve(AUC)就出现了。顾名思义，AUC的值就是处于ROC 曲线下方的那部分面积的大小。通常，AUC的值介于0.5到1.0之间，较大的AUC代表了较好的性能。

为了更加直观的表示算法性能，一般将各个算法曲线放在同一个图中曲线越靠近左上方，说明算法的性能越好。

（2）算法执行效率

大部分应用领域需要实时地检测人脸，如人脸识别、人脸跟踪，视频监控等。在检测率和误检率达到满意的前提下，检测速度越快越好。算法执行效率在理论层面有算法复杂度的分析。在实际测试过程当中，对给定配置的机型，在相同条件下，对$N$张指定大小的图片进行测试，得到总用时为$Ts$，则可得到算法检测帧率为$\frac{N}{T}fps$。
\subsection{实验结果和分析}
实验采用了离散的方案在FDDB上进行人脸检测算法的评估。为此，我们和最新的FDDB上最新的已经发表的结果进行比较
\supercite{li2013learning,chen2014joint,yang2015convolutional,ranjan2015deep,Vijay2015Visual}，与学术界己发表的算法的比较结果如图\ref{fig_publised}所示，与商业系统的比较结果如图\ref{fig_unpublised}所示。
\begin{figure}[!ht] \centering
  \includegraphics[width=.9\textwidth]{figure/fig_fddb_result_1.eps}
  \bicaption[与学术界己发表的算法的比较结果]{学术界己发表的算法的比较结果~\label{fig_publised}}{Comparison with published methods}
\end{figure}
\begin{figure}[!ht] \centering
  \includegraphics[width=.9\textwidth]{figure/fig_fddb_result_2.eps}
  \bicaption[与商业系统的比较结果]{与商业系统的比较结果~\label{fig_unpublised}}{Comparison with published methods}
\end{figure}

图\ref{fig_publised}中与其它方法的比较结果数据由FDDB\footnote{\url{http://vis-www.cs.umass.edu/fddb/results.html}}提供，其中红色箭头（下）对应的方法为基于Haar Adaboost，而蓝色箭头（上）表示我们的基于DPM的算法，ROC曲线越往左上角说明性能越好，可以看出，我们的算法虽然没有最新算法好，但是和基于Adaboost传统方法比较有非常大的提升。而目前开源的算法当中，基于Haar Adaboost的算法还是大多数。而我们的算法是在开源方法当中性能最好的算法。 人脸检测算法从上一结果可以看出，基于DPM的算法虽然没有达到最好的效果，但是却仅次于基于Deep Learning 的方法。而我们基于DPM的人脸检测算法利用了比深度学习少的数据和训练时间。上述最好的算法并没有对算法的检测效率进行比较。我们知道基于Haar Adaboost 算法实时性很高，为此我们跟OpenCV自带的检测器进行了比较了算法的执行效率，其效果如表
\ref{table_opencv}所示。
\begin{table}[]
\centering
\bicaption[与OpenCV人脸检测比较]{与OpenCV人脸检测比较~\label{table_opencv}}{Comparison with OpenCV face detector}
\label{my-label}
\begin{tabular}{ccc}
\toprule[1.5pt]
\multicolumn{1}{l}{\textbf{~~~~~~~~指标~~~~}} & \multicolumn{1}{l}{\textbf{~~~~~~OpenCV~~~}} & \multicolumn{1}{l}{\textbf{~~~~~~Ours~~~}} \\ \hline \toprule[1pt]
~~~~速度~~~~                                & \textless15fps                       & 30fps                              \\
~~~~检测率~~~~                              & 低                                   & 高                                  \\
~~~~误检率~~~~                              & 高                                   & 低                                  \\
~~~~指令集优化~~~~                          & ~~~~20\%提升~~~~                             & ~~~~40\%提升~~~~                             \\ \hline
\toprule[1.5pt]
\end{tabular}
\end{table}

我们的人脸检测器在运行时的时间和内存开销都十分的低。我们和OpenCV中的人脸检测器以及文献\parencite{zhu2012face}中的人脸检测器进行比较，我们比较不同的算法在相同情况下的时间和内存开销。对于所有的方法，我们都在分辨率为720p的图片中检测最小为$80\times80$的人脸。在一个普通的PC上、使用单线程，仅仅花了 31.5ms就能够处理完成。这个速度比文献\parencite{zhu2012face}中的人脸检测器快了1000多倍。OpenCV的人脸检测器需要 62.8ms，而且我们的算法的识别精度要远远高于OpenCV的人脸检测器。同时，在运行时的内存韵方面，我们的人脸检测器仅仅需要20MB的内存。而在其他的方法中，例如文献\parencite{li2014efficient}中的人脸检测器需要150MB的内存，而文献\parencite{shen2013detecting}中的检测器需要866MB的内存。和这些方法相比，我们的人脸检测器更加的实用，特别是在移动设备和嵌入式设备上。
\begin{figure}[!ht] \centering
  \includegraphics[width=.9\textwidth]{figure/fig_opecnv_vs_dlib1.eps}
  \bicaption[]{OpenCV与本文方法在零误检下的比较~\label{fig_opecnv_vs_dlib1}}{OpenCV detector vs. our method in zero false positive}
\end{figure}

\begin{figure}[!ht] \centering
  \includegraphics[width=.9\textwidth]{figure/fig_opecnv_vs_dlib2.eps}
  \bicaption[OpenCV与本文方法在全召回下的比较]{OpenCV与本文方法在全召回下的比较~\label{fig_opecnv_vs_dlib2}}{OpenCV detector vs. our method in full recall}
\end{figure}

图\ref{fig_opecnv_vs_dlib1}和图\ref{fig_opecnv_vs_dlib2}分别展示了基于Opencv的方法和我们的方法在零误检时候和全召回情况下的结果。可以清晰的看到，在图\ref{fig_opecnv_vs_dlib1}中我们的方法和OpenCV当中的人脸检测器在没有任何误检的情况下，我们的方法并未遗漏掉任何人脸。在图\ref{fig_opecnv_vs_dlib2}中我们的方法和OpenCV自带的方法在全部检测到人脸的情况下，OpenCV误检了三个人脸，而我们的方法没有任何误检，再一次证明了我们方法的鲁棒性。这也为后续的人脸特征点检测和识别提供了有效的检测方法。

\section{人脸特征点检测结果与分析}
\subsection{实验数据库与设置}
早期的人脸配准数据集主耍在实验场景下拍摄，而最近的人脸配准数据集往往从实际场景采集。相对实验场景的人脸配准数据库，自然场景的人脸配准数据库在姿态变化、表情、遮挡、光照强度方面面临着更大的挑战。在实验当中，我们采用真实场景下的Helen\supercite{le2012interactive} 和LFPW\supercite{belhumeur2011localizing}这两个数据库进行对比实验。

\textbf{Helen}\supercite{le2012interactive}：Helen人脸数据库是2012年ECCV的论文\parencite{le2012interactive}当中提出的。它包括两个目录，分别为训练样本集和测试样本集。它包含了2330张高分辨率真实场景下的人脸图片，且每个人脸都被精细的194个人脸特征点标记。其中大部分的图片都来自国外社交网站Flickr。其中有2000张作为训练集，330张作为测试集。在Helen数据库当中，每个人脸的大小是550个像素，即使最小的人脸也有150像素。所以它作为一种非常精细的人脸特征点定位基准数据库。其样例图片如图\ref{fig_helen} 所示。
\begin{figure}[!ht] \centering
  \includegraphics[width=.9\textwidth]{figure/fig_helen.eps}
  \bicaption[Helen 数据库样例]{Helen数据库样例~\label{fig_helen}}{Example of Helen dataset}
\end{figure}

\textbf{LFPW}\supercite{belhumeur2011localizing}：该数据库在2011年被Belhumeur等人创建，全名为：Labeled Face Parts in the Wild。数据库是从网络上获取的真实场景下的图片，其中包含了形变、光照、表情、遮挡等恶劣条件的人脸照片。其目的是为了测试人脸配准（人脸特征点检测）在真实无限制条件下的性能。由于该数据库只提供了图片的网络地址，但是一些网络地址不是一直有效，因此，我们只从网络上获取到了包含1100张训练集当中的810张，以及包含300张测试集当中的240张。该数据库的每张人脸都被三个MTurk\footnote{\url{https://www.mturk.com/mturk/welcome}}工人所标记，其中的人脸照片都被标记了29个特征点。为了获取到足够多的数据，我们按照文章\parencite{belhumeur2011localizing}的方式，将训练集增加到2000张并用得到的240张做测试集。其样例图片如图\ref{fig_lfpw} 所示。
\begin{figure}[!ht] \centering
  \includegraphics[width=.9\textwidth]{figure/fig_lfpw.eps}
  \bicaption[LFPW 数据库样例]{LFPW数据库样例~\label{fig_lfpw}}{Examples of LFPW dataset}
\end{figure}

为了分析这两个数据库的数据分布，我们对这两个数据库在表情、姿态、遮挡这三个方面进行统计，其具体情况如表\ref{table_dataset_distribution}所示：
\begin{table}[]
\centering
\bicaption[数据库数据分布]{数据库数据分布~\label{table_dataset_distribution}}{Distribution of the datasets}
\newsavebox{\tablebox}
\begin{lrbox}{\tablebox}
\begin{tabular}{|c|c|c>|c|c|c|c|c|c|c|}
\toprule[1.5pt]
\textbf{数据集} & \multicolumn{6}{c|}{\textbf{表情}} & \multicolumn{2}{c|}{\textbf{姿态}} & \textbf{遮挡} \\ \hline
 & 中性 & 微笑 & 惊讶 & 恶心 & 尖叫 & 斜视 & 0°-15° & 15°-30° &  \\ \hline
\textbf{LFPW} & 48.66\% & 39.73\% & 8.05\% & 0.44\% & 1.78\% & 1.34\% & 94.69\% & 5.31\% & 18.31\% \\ \hline
\textbf{Helen} & 43.03\% & 49.09\% & 2.12\% & 2.43\% & 0.00\% & 3.33\% & 94.54\% & 5.46\% & 13.03\% \\ \hline
\toprule[1.5pt]
\end{tabular}
\end{lrbox}
\scalebox{0.9}{\usebox{\tablebox}}  %缩放表格
\end{table}

\subsection{性能评价准则}
通常人脸特征点的评价准则比较依赖于人脸特征点的个数。常见的m17人脸关键点定位误差评价标准采用了十七个关键点(眉毛四个，眼睛六个，鼻子三个，嘴巴四个)，而m7评价标准采用了眼角、嘴角及鼻尖的七个关键点定位。关键点定位主要有两个评价指标：与手工标定比较得化定位误差与定位效率。归一化均方误差(Normalized Mean Error，NME)是常常用来衡量定位效果的主要指标，即：
\begin{equation}
\label{equ_NME}
E_i=\frac{\frac{1}{M} \sum_{j=1}^{M}|p_{i,j}-g_{i,j}|_2}{|l_i-r_i|_2}
\end{equation}
其中，$i$表示图像标号，$j$为关键点标号，$M$是关键点的数目，$l_i$是左瞳孔中心的位置，$r_i$是心瞳孔中心的位置。$|l_i-r_i|_2$表示瞳孔距离IOD(Inter-Ocular Distance，IOD)，采用欧氏距离用以归一化配准误差。$p_{i,j}$是第$i$张图片的第$j$个特征点的预测值。$g_{i,j}$是第$i$张图片的第$j$个特征点的实际值。一般在计算之前，都将人脸图片根据瞳孔中心的位置归一化到固定距离，其原理是一致的。

如图\ref{fig_nme_iod}所示，因为配准误差是各向同性的，红绿蓝三个圆分别表示眼角关键点定位归一化均方误差为$0.05IOD$、$0.1IOD$以及$0.2IOD$。通常也会有对误差设限进行配准评价，通常设在
$0.05IOD\sim0.10IOD$。在我们的方法中，我们采取了文献\parencite{dantone2012real}中所采用的方法，我们认为如果定位误差超过10\%那么就是定位失败。
\begin{figure}[!ht] \centering
  \includegraphics[width=.5\textwidth]{figure/fig_nme_iod.eps}
  \bicaption[眼角定位误差示例]{眼角定位误差示例（红：0.05IOD、绿：0.1IOD、 蓝：0.2IOD）~\label{fig_nme_iod}}[Illustration of localization error]{Illustration of localization error(Red:0.05IOD,Green:0.1IOD, Blue:0.2IOD)}
\end{figure}
\subsection{实验结果和分析}
为了证明我们算法的精度和速度，我们分别在Helen和LFPW上两个数据上进行了指定标准的测试，并且对两个数据库算法执行效率进行了实验。实验的参数设置分别与方法ESR\supercite{Cao2012Face}和方法RCPR\supercite{Burgosartizzu2013Robust}保持一致。其实验结果由表\ref{table_result_lfpw}和\ref{table_result_Helen}分别所示。
\begin{table}[ht]
\centering
\bicaption[LFPW数据库测试结果]{LFPW数据库测试结果~\label{table_result_lfpw}}{Results on LFPW}
\begin{tabular}{cccc}
\toprule[1.5pt]
\multicolumn{1}{l}{Method} & \multicolumn{1}{l}{Error} & \multicolumn{1}{l}{Failures} & \multicolumn{1}{l}{FPS} \\ \hline \toprule[1pt]
ESR & 3.8 & 4\% & 3 \\
RCPR & 3.5 & 2\% & 12 \\
Human & 3.28 & 0\% & - \\
\textbf{Ours} & \textbf{3.44} & \textbf{2\%} & \textbf{20} \\ \hline
\toprule[1.5pt]
\end{tabular}
\end{table}

\begin{table}[ht]
\centering
\bicaption[Helen数据库测试结果]{Helen数据库测试结果~\label{table_result_Helen}}{Results on Helen}
\begin{tabular}{cccc}
\toprule[1.5pt]
\multicolumn{1}{l}{Method} & \multicolumn{1}{l}{Error} & \multicolumn{1}{l}{Failures} & \multicolumn{1}{l}{FPS} \\ \hline  \toprule[1pt]
ESR & 7.1 & 13\% & 2 \\
RCPR & 6.5 & 8\% & 6 \\
Human & 3.3 & 0\% & - \\
\textbf{Ours} & \textbf{6.7} & \textbf{9\%} & \textbf{13} \\ \hline
\toprule[1.5pt]
\end{tabular}
\end{table}

可以看出，我们的方法不仅保证了针对多姿态形变、表情、遮挡情况下的低错误率，而且由于我们提出的自适应初始化的策略，使得算法执行的效率很高。在Helen数据库上，我们在实验的过程当中，根据不同的迭代次数，可以得到对应的平均误差，为此我们比较了与其它方法的收敛性能，如图\ref{fig_landmark_fast}所示。
\begin{figure}[!ht] \centering
  \includegraphics[width=.6\textwidth]{figure/fig_landmark_fast.eps}
  \bicaption[快速收敛示例]{快速收敛示例~\label{fig_landmark_fast}}{Illustration of fast convergence}
\end{figure}

由图\ref{fig_landmark_fast}可以看出，采用了自适应的初始化策略之后，使得算法在保证定位精度的前提下有更快的收敛速度，这也再次体现了我们的算法鲁棒性。Helen数据库图像分辨率很高，并且标注的关键点非常密集，其特征定位也更加精细。但是随着定位点的增多，回归的次数也会增加，从而降低了算法的执行效率，所以在Helen数据库上的帧率远低于在LFPW上的帧率。这也指导我们在实际的工程应用当中，特征点数和速度之间要有一个折中，通常我们会选择十几个特征点作为后续的处理。最后给出算法在不同数据库上的样例检测结果，如图\ref{fig_landmark_results}所示。
\begin{figure}[!ht] \centering
  \includegraphics[width=.8\textwidth]{figure/fig_landmark_results.eps}
  \bicaption[人脸特征点定位结果示例]{人脸特征点定位结果示例~\label{fig_landmark_results}}{Example result of the two dataset}
\end{figure}

\section{人脸识别结果与分析}
\subsection{实验数据库与设置}
\textbf{LFW}\supercite{huang2007labeled}：LFW（Labeled Faces in the Wild）数据库是由美国马萨诸塞大学（ University of Massachusetts）阿姆斯特分校（ Amherst ）计算机视觉实验室整理完成，对应文章为一篇技术报告，该实验室还共同维护了上文讲到的FDDB人脸检测基准数据库。其主要目的用于研究非受限情形下的人脸识别问题，且现已成为学术界和工业界评价人脸识别性能的基准数据集（benchmark）。LFW包含了13233张自然状态下人脸图片，其大多为名人，包含了5749个人，其中4069个人只有一张图片，1680个人多于一张图片。LFW 的测试任务是判断一对人脸照片是来自同一个人还是不同的人。测试集包含 6000 对人脸图像。对于人脸识别问题，包含人脸确认（Face Verification）和人脸辨识（Face Identification）两个任务，在该数据库上，主要是人脸确认的任务。在我们的实验过程当中，利用该数据库测试了基于KISSME的人脸确认任务，其目的在于验证其度量方式的有效性。LFW数据库样例图片如下图\ref{fig_lfw_dataset}所示。可以看出，该数据库包含了多姿态、表情、光照和部分遮挡情况下的人脸图片，其难点与监控环境下的人脸识别面对的挑战一致。
\begin{figure}[!ht] \centering
  \includegraphics[width=.8\textwidth]{figure/fig_lfw_dataset.eps}
  \bicaption[LFW数据库样例图片]{LFW数据库样例图片~\label{fig_lfw_dataset}}{Example of LFW dataset}
\end{figure}

\textbf{Pubfig}\supercite{attribute_classifiers}：Public Figures Face Database(PubFig)\supercite{attribute_classifiers}数据库是一个真实条件下巨大的人脸数据库，它包含了200个人的58797图片，其中大部分图片都是从网上收集得到。该数据库包含训练集和测试集两部分：其中训练集包含60个人。该部分用来训练算法本身，为了防止过拟合等问题，该数据集与测试集并没有任何重叠和交集。测试集包含了140个人，主要用于测试算法性能。

由于版权问题，该数据库并只开放了这些图片的网络链接，由于图片的链接会慢慢消失，工作人员会定期更新不能用的链接，让其能够近似比较。由于该数据库数量巨大，虽然不能精确比较算法性能，但是在近似情况下，整体的性能与原始的数据集图片并无太大差别。

由于该数据集从真实环境下获得，所以仍然保持着真实条件下姿态、光照、表情等影响因素，因此十分有挑战性。另一方面，在提出该数据库的文章\parencite{attribute_classifiers}中，提出了高级的人脸属性描述，其中包括了73个人脸属性，例如性别、种族、头发颜色等等。在后续的特征提取实验中，本文也采用了该特征提取的方法，以便统一的比较。该数据库示例图片如图\ref{fig_pubfig_dataset}所示。
\begin{figure}[!ht] \centering
  \includegraphics[width=.8\textwidth]{figure/fig_pubfig_dataset.eps}
  \bicaption[PubFig数据库样例图片]{PubFig数据库样例图片(图片下面数字代表每个人的图片个数)~\label{fig_pubfig_dataset}}[Example of LFW dataset]{Example of LFW dataset (Below each image is the total number of images for that person)}
\end{figure}
\subsection{性能评价准则}
上文提到，人脸识别分为人脸确认（Face Verification）和人脸辨识（Face Identification）两种任务。人脸确认判断两张人脸图像是否属于同一个人，本质上是属于一个二分类问题，所以我们采用ROC曲线来评价人脸确认任务的性能。关于ROC曲线的说明上文已经提到，此部分再不做说明。

人脸辨识是将一张人脸图像分成$N$个身份类别之一，其本质上是属于一个多分类问题，且难度随着$N$变大而增加。2014年，阿尼尔・ 简(Anil Jain)的研究小组提出了在LFW上人脸辨识任务的测试协议
\supercite{Best2014Unconstrained}。 这是一对多的匹配， 比一对一的人脸确认难度高很多。该测试协议包含基于封闭集和开放集两种不同的人脸辨识任务。 在封闭集上报告的是 Rank-1辨识率，开放集上报告的是在 1\% 的虚警率下 Rank-1 的检测和辨识率 (DIR\@1\% FAR)。

由于本文方法采用了多任务度量的机制，在每个任务上需要同一个人的不止一张的人脸数据作为训练，所以采用了PubFig数据库作为人类辨识的测试数据集。为了在同样数据库上进行比较，我们跟文章
\parencite{kostinger2012synergy}采用了相同的评价机制，即通过召回率曲线（Precision Recall Curve，PRC）的方式，我们对分类器的得分进行了排序，通过不同的阈值得到不同的预测结果。其中，横轴召回表示测试样本被标记（分类）所占的百分比，其中标记意味着测试样本的分类器得分大于了当前设定的阈值（我们认为只有当分类器结果大于指定阈值的时候才指定相应标签），那么纵轴对应的准确率表示被正确分类的样本比例。

根据表\ref{table_roc}混淆矩阵的定义，我们可以得到对Recall和Precision的定义，即：
\begin{equation}
\label{equ_prc_1}
Recall=TP/P,~P=TP+FN
\end{equation}
\begin{equation}
\label{equ_prc_2}
Precision=TP/(TP+FP)
\end{equation}
在这里，Recall代表测试样本中被指定类别标签的百分比，而Precision表示在所有指定类别标签的这些样本中被正确分类的比例。
\subsection{实验结果和分析}
为了证明基于KISSME度量学习的有效性，我们在LFW上数据库上进行了测试，并重现了文献\parencite{kissme}的方法。实验过程中采用了数据库当中的十折交叉验证方式，平均每个集合有包含300个相似对和300个不相似对，最终的结果是交叉验证的平均结果。在实验当中，特征表达采用了文献\parencite{Guillaumin}所采用的方法。

首先，我们根据人脸特征点检测之后的6个特征点（嘴角2个，眼睛3个，鼻子1个）在三个尺度上提取SIFT\supercite{Lowe2004Distinctive}特征。相应的特征维数是3456维。为了便于计算，我们利用PCA将特征维度降至100维的子空间。为了保证公平性，也验证了未降维的2456维特征，可以发现PCA降维对其影响较小。只有通过线性的SVM方法去分类受部分影响。
\begin{figure}[!ht] \centering
  \includegraphics[width=.8\textwidth]{figure/fig_lfw_kissme_roc.eps}
  \bicaption[LFW数据库KISSME人脸确认结果]{LFW数据库KISSME人脸确认结果.(a) 相似对和不相似对示例 (b)不同方法对应的ROC曲线~\label{fig_lfw_kissme_roc}}[Face verification results on the LFW dataset]{Face verification results on the LFW dataset.(a) Examples of similar and dissimilar pairs. (b) ROC curves for different method.}
\end{figure}
在图\ref{fig_lfw_kissme_roc}当中，我们与常用的度量学习方法进行了比较，如LDML\supercite{Guillaumin}，ITML\supercite{itml}，LMNN\supercite{weinberger09distance}，SVM\supercite{Chang2011LIBSVM}以及马氏距离、欧式距离作为基准进行比较。可以发现，本方法取得比其它度量学习方法性能稍微提升。

为了进一步测试，我们在PubFig上数据库上进行了测试，其测试数据也基于十折交叉验证，每个集合包含了1000个相似对和1000个不相似对，每个集合都来自14个不同的人。并且测试集当中没有出现训练集当中的人。其中采取了该数据库所在文章提供的“high-level”的属性特征。同样，我们与LDML\supercite{Guillaumin}，ITML\supercite{itml}，LMNN\supercite{weinberger09distance}，SVM\supercite{Chang2011LIBSVM}以及两个基准方法进行比较，其效果图\ref{fig_kissme_pubfig_roc}所示。可以看出，基于KISSME的性能整体上仍然是最好的。
\begin{figure}[!ht] \centering
  \includegraphics[width=.5\textwidth]{figure/fig_kissme_pubfig_roc.eps}
  \bicaption[PubFig数据库KISSME人脸确认结果]{PubFig数据库KISSME人脸确认结果~\label{fig_kissme_pubfig_roc}}{Face verification results on the PubFig dataset.}
\end{figure}

KISSME度量学习方法最大的特定是训练时间短，执行效率高。上述实验证明了其识别的准确率，可以看出相比其它方法虽然都有一定程度的提升，虽然与一些方法的提升效果不是很明显，但是算法执行效率却相差巨大。为了验证其执行效率，我们比较了不同度量学习方法的训练时间，其测试机型为3.06GHZ Xeon 24核服务器。如表\ref{table_ave_trainningtime}所示。
\begin{table}[ht]
\centering
\bicaption[平均训练时间]{平均训练时间~\label{table_ave_trainningtime}}{Average training times}
\begin{tabular}{cccccc}
\toprule[1.5pt]
\diagbox{\textbf{Dataset}}{\textbf{Method}} & \textbf{KISSME} & \textbf{SVM} & \textbf{ITML} & \textbf{LDML} & \textbf{LMNN} \\ \hline  \toprule[1pt]
\textbf{LFW}    & \textbf{0.05s} & 12.78s & 24.81s & 307.23s & 1198.69s \\
\textbf{PubFig} & \textbf{0.07s} & 0.84s & 20.82 & 2868.91s & 783.66s \\ \hline
\toprule[1.5pt]
\end{tabular}
\end{table}
由表\ref{table_ave_trainningtime}可以看出，KISSME方法的训练时间非常快，这得益于该方法不需要额外的优化，而传统的度量学习方法将问题转化为可解的优化问题，但计算过程迭代次数较多，计算缓慢。相反，KISSME方法具有简单、快速、有效的特点避免了复杂度高的迭代过程，同时性能优于ITML、 LMNN等方法。该结果与文章\parencite{kissme}所示的结果基本一致。这也为我们将该方法拓展到两级的度量学习任务用于人脸辨识任务提供了基础。

为了证明我们提出的两级度量学习任务的有效性，我们在PubFig数据库上进行了人脸辨识任务的验证。首先，在第一级的任务中，我们分期提取了LBP\supercite{Ojala2002Gray}、SIFT\supercite{Lowe2004Distinctive}和高级的属性特征\supercite{attribute_classifiers}。按照评价准则及测试标准，我们首先跟单任务的KISSME方法、以及多任务的KISSME方法进行了比较。如图\ref{fig_tmtl_pubfig} (a)所示，我们的方法（TMTL)在全召回率的情况下得到了71.2\%的准确率。并且证明了多任务的执行效果比单任务的效果更好。
\begin{figure}[!ht] \centering
  \includegraphics[width=.95\textwidth]{figure/fig_tmtl_pubfig.eps}
  \bicaption[PubFig数据库TMTL人脸辨识结果]{TMTL与(a)单任务KISSME和MT-KISSME， (b)其它多任务方法比较~\label{fig_tmtl_pubfig}}[Face identification results on the PubFig dataset]{Comparison with (a) single-task learning and MT-KISSME, (b) other MTL methods.}
\end{figure}

紧接着，我们与其它多任务的度量学习方法MT-LMNN\supercite{parameswaran2010large}和多分类SVM\supercite{Chang2011LIBSVM}进行了比较。由图\ref{fig_tmtl_pubfig} (b)可以看出，我们的方法比多分类SVM（one-vs-all）和MT-LMNN分别高9.4\%和10.6\%。这也证明了我们的两级度量方法从相似对以及特定任务的学习中获取了更多的信息，从而提高了识别率。
\section{本章小结}
本章主要对人脸检测、人脸特征点定位、人脸识别这三个任务进行了实验验证。其中人脸检测验证了基于DPM方法的人脸检测效果，实验得出该方法可以实时的鲁棒的检测出多视角的人脸。在人脸特征点定位当中，验证了两级级联回归的特征点定位方法，并验证了我们提出的自适应初始化方法的有效性，为实时的特征点定位提供了保证，实验得出，该方法可以实时准确的定位出人脸特征点的位置，为后续人脸识别任务提供了有效的归一化操作。在人脸识别任务中有两部分内容，针对人脸确认任务，本章验证了基于KISSME方法在人脸确认任务当中的准确性和高效性，并分别在两个真实数据库下进行了实验。针对人脸辨识任务，验证了本文提出的两级多任务度量学习（TMTL）有效性，实验证明，本方法在人脸辨识任务中取得了比单任务学习及其它多任务度量方法更好的性能。
